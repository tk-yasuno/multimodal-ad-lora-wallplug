{
  "session_id": "20250928_165841",
  "start_time": "2025-09-28T16:58:41.979953",
  "anomaly_detection": {
    "status": "success",
    "training_time": 68.523998,
    "output": " - wallplugs_trainer - INFO - Model setup complete:\n2025-09-28 16:59:02,779 - wallplugs_trainer - INFO -   Total parameters: 67,170,604\n2025-09-28 16:59:02,779 - wallplugs_trainer - INFO -   Trainable parameters: 67,170,604\n2025-09-28 16:59:02,790 - wallplugs_trainer - INFO -   Device: cuda\n2025-09-28 16:59:02,790 - wallplugs_trainer - INFO -   MiniCPM enabled: True\n2025-09-28 16:59:02,790 - wallplugs_trainer - INFO - Optimizer setup complete:\n2025-09-28 16:59:02,790 - wallplugs_trainer - INFO -   LR: 0.0001\n2025-09-28 16:59:02,790 - wallplugs_trainer - INFO -   Weight decay: 1e-05\n2025-09-28 16:59:02,795 - wallplugs_trainer - INFO - ============================================================\n2025-09-28 16:59:02,795 - wallplugs_trainer - INFO - \nEpoch 1/50\n2025-09-28 16:59:02,795 - wallplugs_trainer - INFO - ------------------------------\n\nTraining failed: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number\n",
    "model_path": "models/minicpm_autoencoder_wallplugs_best.pth"
  },
  "lora_explanation": {
    "status": "success",
    "training_time": 24.102941,
    "output": "- INFO - Loading model: Salesforce/blip-image-captioning-base\ntrainable params: 1,474,560 || all params: 225,446,204 || trainable%: 0.6541\n2025-09-28 17:00:17,130 - wallplugs_lora_trainer - INFO - Model setup complete\ntrain dataset: 112 samples\nvalidation dataset: 61 samples\n2025-09-28 17:00:17,134 - wallplugs_lora_trainer - INFO - Data setup complete:\n2025-09-28 17:00:17,136 - wallplugs_lora_trainer - INFO -   Train samples: 112\n2025-09-28 17:00:17,136 - wallplugs_lora_trainer - INFO -   Val samples: 61\n2025-09-28 17:00:17,136 - wallplugs_lora_trainer - INFO - ============================================================\n2025-09-28 17:00:17,324 - wallplugs_lora_trainer - INFO - Pre-training sample generation...\n2025-09-28 17:00:20,979 - wallplugs_lora_trainer - ERROR - Training failed: BlipForConditionalGeneration.forward() got an unexpected keyword argument 'inputs_embeds'\n\nLoRA training failed: BlipForConditionalGeneration.forward() got an unexpected keyword argument 'inputs_embeds'\n",
    "model_path": "models/lora_wallplugs/final_model"
  },
  "integration_test": {
    "status": "warning",
    "test_time": 3.603455,
    "error": "Traceback (most recent call last):\n  File \"C:\\Users\\yasun\\MAD-FH\\test_wallplugs_fodd.py\", line 44, in test_fodd_with_wallplugs\n    from fodd_pipeline import FODDPipeline\n  File \"C:\\Users\\yasun\\MAD-FH\\fodd_pipeline.py\", line 19, in <module>\n    import cv2\nModuleNotFoundError: No module named 'cv2'\nTraceback (most recent call last):\n  File \"C:\\Users\\yasun\\MAD-FH\\test_wallplugs_fodd.py\", line 189, in <module>\n    create_sample_analysis()\n  File \"C:\\Users\\yasun\\MAD-FH\\test_wallplugs_fodd.py\", line 179, in create_sample_analysis\n    print(f\"\\n\\U0001f5bc\\ufe0f  分析対象: {category}/{img_file.name}\")\nUnicodeEncodeError: 'cp932' codec can't encode character '\\U0001f5bc' in position 2: illegal multibyte sequence\n",
    "output": "MVTec AD Wallplugs x FODD パイプライン テスト\n[ERROR] テスト実行エラー: No module named 'cv2'\n\n[SAMPLE] 個別サンプル分析例\n"
  },
  "summary": {
    "overall_status": "success",
    "anomaly_detection_success": true,
    "lora_explanation_success": true,
    "integration_test_ok": true,
    "total_training_time": 92.62693900000001,
    "end_time": "2025-09-28T17:00:26.238086"
  }
}