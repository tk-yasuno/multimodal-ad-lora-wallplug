{
  "session_id": "20250928_170702",
  "start_time": "2025-09-28T17:07:02.851706",
  "anomaly_detection": {
    "status": "success",
    "training_time": 69.38309,
    "output": " - wallplugs_trainer - INFO - Model setup complete:\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   Total parameters: 67,170,604\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   Trainable parameters: 67,170,604\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   Device: cuda\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   MiniCPM enabled: True\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO - Optimizer setup complete:\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   LR: 0.0001\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO -   Weight decay: 1e-05\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO - ============================================================\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO - \nEpoch 1/50\n2025-09-28 17:07:24,969 - wallplugs_trainer - INFO - ------------------------------\n\nTraining failed: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number\n",
    "model_path": "models/minicpm_autoencoder_wallplugs_best.pth"
  },
  "lora_explanation": {
    "status": "success",
    "training_time": 111.902699,
    "output": "ng): BlipForConditionalGeneration.forward() got an unexpected keyword argument 'inputs_embeds'\n2025-09-28 17:10:10,139 - wallplugs_lora_trainer - WARNING - Batch error (skipping): BlipForConditionalGeneration.forward() got an unexpected keyword argument 'inputs_embeds'\n2025-09-28 17:10:10,325 - wallplugs_lora_trainer - WARNING - Batch error (skipping): BlipForConditionalGeneration.forward() got an unexpected keyword argument 'inputs_embeds'\n2025-09-28 17:10:10,714 - wallplugs_lora_trainer - INFO - Model saved to: models\\lora_wallplugs\\final_model\n2025-09-28 17:10:10,718 - wallplugs_lora_trainer - INFO - Custom training completed successfully!\n\nLoRA training completed successfully!\n   Model saved: models\\lora_wallplugs\\final_model\n   Training results: models/lora_wallplugs/training_results.json\n   Training report: models/lora_wallplugs/training_report.md\n\nNext steps:\n1. Test the trained LoRA model with FODD pipeline\n2. Evaluate explanation quality\n3. Fine-tune hyperparameters if needed\n",
    "model_path": "models/lora_wallplugs/final_model"
  },
  "integration_test": {
    "status": "success",
    "test_time": 3.657944,
    "output": "MVTec AD Wallplugs x FODD パイプライン テスト\n[ERROR] テスト実行エラー: No module named 'cv2'\n\n[SAMPLE] 個別サンプル分析例\n\n[IMAGE] 分析対象: train/normal/000_regular.png\n   パス: data\\processed\\wallplugs\\train\\normal\\000_regular.png\n   コマンド例:\n   python -c \"from fodd_pipeline import FODDPipeline; p=FODDPipeline(); print(p.process_single_image('data\\processed\\wallplugs\\train\\normal\\000_regular.png'))\"\n\n[IMAGE] 分析対象: train/anomalous/000_overexposed.png\n   パス: data\\processed\\wallplugs\\train\\anomalous\\000_overexposed.png\n   コマンド例:\n   python -c \"from fodd_pipeline import FODDPipeline; p=FODDPipeline(); print(p.process_single_image('data\\processed\\wallplugs\\train\\anomalous\\000_overexposed.png'))\"\n"
  },
  "summary": {
    "overall_status": "success",
    "anomaly_detection_success": true,
    "lora_explanation_success": true,
    "integration_test_ok": true,
    "total_training_time": 181.285789,
    "end_time": "2025-09-28T17:10:15.864040"
  }
}