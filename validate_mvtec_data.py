"""
MVTec AD Wallplugs ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¢ºèªã¨MAD-FHã‚·ã‚¹ãƒ†ãƒ ã§ã®ä½¿ç”¨å¯èƒ½æ€§ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
from pathlib import Path
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import json
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¨­å®š
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

class MVTecDataValidator:
    """MVTec ADå‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_name="wallplugs"):
        self.dataset_name = dataset_name
        self.data_dir = Path(f"data/processed/{dataset_name}")
        self.stats_file = self.data_dir / "preprocessing_stats.json"
        
        # çµ±è¨ˆæƒ…å ±èª­ã¿è¾¼ã¿
        if self.stats_file.exists():
            with open(self.stats_file, 'r', encoding='utf-8') as f:
                self.preprocessing_stats = json.load(f)
        else:
            self.preprocessing_stats = None
    
    def verify_data_structure(self):
        """ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª"""
        print(f"ğŸ” {self.dataset_name} ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª")
        
        required_dirs = [
            "train/normal",
            "train/anomalous", 
            "validation/normal",
            "validation/anomalous"
        ]
        
        structure_ok = True
        for dir_path in required_dirs:
            full_path = self.data_dir / dir_path
            if full_path.exists():
                count = len(list(full_path.glob("*.png")))
                print(f"  âœ… {dir_path}: {count}æš")
            else:
                print(f"  âŒ {dir_path}: å­˜åœ¨ã—ã¾ã›ã‚“")
                structure_ok = False
        
        return structure_ok
    
    def verify_image_quality(self, sample_count=5):
        """ç”»åƒå“è³ªã®ç¢ºèª"""
        print(f"\nğŸ–¼ï¸  ç”»åƒå“è³ªç¢ºèªï¼ˆã‚µãƒ³ãƒ—ãƒ«{sample_count}æšï¼‰")
        
        # å„ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰ ã‚µãƒ³ãƒ—ãƒ«å–å¾—
        categories = [
            ("train/normal", "æ­£å¸¸è¨“ç·´"),
            ("train/anomalous", "ç•°å¸¸è¨“ç·´"),
            ("validation/normal", "æ­£å¸¸æ¤œè¨¼"),
            ("validation/anomalous", "ç•°å¸¸æ¤œè¨¼")
        ]
        
        quality_results = {}
        
        for category_path, category_name in categories:
            full_path = self.data_dir / category_path
            if not full_path.exists():
                continue
                
            image_files = list(full_path.glob("*.png"))[:sample_count]
            
            sizes = []
            modes = []
            file_sizes = []
            
            print(f"\n  ğŸ“ {category_name} ({len(image_files)}ã‚µãƒ³ãƒ—ãƒ«):")
            
            for img_file in image_files:
                try:
                    # ç”»åƒæƒ…å ±å–å¾—
                    with Image.open(img_file) as img:
                        sizes.append(img.size)
                        modes.append(img.mode)
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
                    file_size_kb = img_file.stat().st_size / 1024
                    file_sizes.append(file_size_kb)
                    
                    print(f"    âœ… {img_file.name}: {img.size}, {img.mode}, {file_size_kb:.1f}KB")
                    
                except Exception as e:
                    print(f"    âŒ {img_file.name}: ã‚¨ãƒ©ãƒ¼ {e}")
            
            # çµ±è¨ˆæƒ…å ±
            if sizes:
                unique_sizes = list(set(sizes))
                unique_modes = list(set(modes))
                avg_file_size = np.mean(file_sizes)
                
                quality_results[category_name] = {
                    "sample_count": len(image_files),
                    "sizes": unique_sizes,
                    "modes": unique_modes,
                    "avg_file_size_kb": avg_file_size
                }
                
                print(f"    ğŸ“Š ã‚µã‚¤ã‚º: {unique_sizes}")
                print(f"    ğŸ“Š ãƒ¢ãƒ¼ãƒ‰: {unique_modes}")
                print(f"    ğŸ“Š å¹³å‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {avg_file_size:.1f}KB")
        
        return quality_results
    
    def create_sample_visualization(self, samples_per_category=2):
        """ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®å¯è¦–åŒ–"""
        print(f"\nğŸ¨ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒå¯è¦–åŒ–ï¼ˆå„ã‚«ãƒ†ã‚´ãƒª{samples_per_category}æšï¼‰")
        
        categories = [
            ("train/normal", "Train Normal"),
            ("train/anomalous", "Train Anomalous"),
            ("validation/normal", "Val Normal"),
            ("validation/anomalous", "Val Anomalous")
        ]
        
        fig, axes = plt.subplots(len(categories), samples_per_category, 
                                figsize=(samples_per_category*4, len(categories)*3))
        
        if len(categories) == 1:
            axes = axes.reshape(1, -1)
        if samples_per_category == 1:
            axes = axes.reshape(-1, 1)
        
        visualization_created = False
        
        for row, (category_path, category_name) in enumerate(categories):
            full_path = self.data_dir / category_path
            
            if full_path.exists():
                image_files = list(full_path.glob("*.png"))[:samples_per_category]
                
                for col, img_file in enumerate(image_files):
                    try:
                        with Image.open(img_file) as img:
                            # RGBå¤‰æ›
                            if img.mode != 'RGB':
                                img_rgb = img.convert('RGB')
                            else:
                                img_rgb = img
                            
                            axes[row, col].imshow(np.array(img_rgb))
                            axes[row, col].set_title(f"{category_name}\n{img_file.name}", 
                                                   fontsize=10)
                            axes[row, col].axis('off')
                            visualization_created = True
                    
                    except Exception as e:
                        axes[row, col].text(0.5, 0.5, f"Error:\n{str(e)}", 
                                          ha='center', va='center')
                        axes[row, col].axis('off')
                
                # ä¸è¶³åˆ†ã¯ç©ºç™½
                for col in range(len(image_files), samples_per_category):
                    axes[row, col].axis('off')
        
        if visualization_created:
            plt.tight_layout()
            output_path = self.data_dir / f"{self.dataset_name}_samples.png"
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"  âœ… ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä¿å­˜: {output_path}")
        else:
            plt.close()
            print(f"  âš ï¸ ã‚µãƒ³ãƒ—ãƒ«ç”»åƒä½œæˆã«å¤±æ•—")
        
        return visualization_created
    
    def test_mad_fh_integration(self):
        """MAD-FHã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ”§ MAD-FHçµ±åˆãƒ†ã‚¹ãƒˆ")
        
        integration_results = {
            "preprocessor_compatible": False,
            "autoencoder_compatible": False,
            "fodd_compatible": False,
            "test_results": {}
        }
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†äº’æ›æ€§ãƒ†ã‚¹ãƒˆ
            from src.data.preprocess import ImagePreprocessor
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            config_path = Path("config/config.yaml")
            if config_path.exists():
                preprocessor = ImagePreprocessor(str(config_path))
                
                # ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã§ãƒ†ã‚¹ãƒˆ
                sample_image = next(iter((self.data_dir / "train/normal").glob("*.png")))
                processed = preprocessor.preprocess_single_image(str(sample_image))
                
                integration_results["preprocessor_compatible"] = True
                integration_results["test_results"]["preprocessor"] = {
                    "input_shape": processed.shape if hasattr(processed, 'shape') else str(type(processed)),
                    "sample_file": sample_image.name
                }
                print(f"  âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†: äº’æ›æ€§OK")
                print(f"     å…¥åŠ›å½¢çŠ¶: {processed.shape if hasattr(processed, 'shape') else type(processed)}")
            
        except Exception as e:
            print(f"  âŒ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†: ã‚¨ãƒ©ãƒ¼ {e}")
            integration_results["test_results"]["preprocessor_error"] = str(e)
        
        try:
            # 2. FODD Pipelineäº’æ›æ€§ãƒ†ã‚¹ãƒˆ
            from fodd_pipeline import FODDPipeline
            
            # FODD PipelineåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯ã—ãªã„ï¼‰
            pipeline = FODDPipeline()
            integration_results["fodd_compatible"] = True
            print(f"  âœ… FODD Pipeline: åˆæœŸåŒ–OK")
            
        except Exception as e:
            print(f"  âš ï¸ FODD Pipeline: ã‚¨ãƒ©ãƒ¼ {e}")
            integration_results["test_results"]["fodd_error"] = str(e)
        
        return integration_results
    
    def generate_validation_report(self):
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print(f"\nğŸ“Š æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
        
        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª
        structure_ok = self.verify_data_structure()
        
        # ç”»åƒå“è³ªç¢ºèª
        quality_results = self.verify_image_quality()
        
        # å¯è¦–åŒ–ä½œæˆ
        viz_created = self.create_sample_visualization()
        
        # MAD-FHçµ±åˆãƒ†ã‚¹ãƒˆ
        integration_results = self.test_mad_fh_integration()
        
        # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        report = {
            "dataset_name": self.dataset_name,
            "validation_timestamp": datetime.now().isoformat(),
            "data_structure": {
                "valid": structure_ok,
            },
            "image_quality": quality_results,
            "visualization_created": viz_created,
            "mad_fh_integration": integration_results,
            "preprocessing_stats": self.preprocessing_stats
        }
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_file = self.data_dir / f"{self.dataset_name}_validation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"  âœ… æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        
        return report
    
    def print_summary(self, report):
        """æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "="*60)
        print(f"ğŸ¯ MVTec AD {self.dataset_name} æ¤œè¨¼å®Œäº†")
        print("="*60)
        
        if self.preprocessing_stats:
            stats = self.preprocessing_stats["dataset_info"]
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±:")
            print(f"   ç·ç”»åƒæ•°: {stats['processed_total']}æš")
            print(f"   è¨“ç·´ç”¨æ­£å¸¸: {stats['train_normal']}æš")
            print(f"   è¨“ç·´ç”¨ç•°å¸¸: {stats['train_anomalous']}æš") 
            print(f"   æ¤œè¨¼ç”¨æ­£å¸¸: {stats['val_normal']}æš")
            print(f"   æ¤œè¨¼ç”¨ç•°å¸¸: {stats['val_anomalous']}æš")
            print(f"   ç”»åƒã‚µã‚¤ã‚º: {stats['target_size'][0]}Ã—{stats['target_size'][1]}")
        
        print(f"\nâœ… æ¤œè¨¼çµæœ:")
        print(f"   ãƒ‡ãƒ¼ã‚¿æ§‹é€ : {'OK' if report['data_structure']['valid'] else 'NG'}")
        print(f"   ç”»åƒå“è³ª: {'OK' if report['image_quality'] else 'NG'}")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–: {'OK' if report['visualization_created'] else 'NG'}")
        
        integration = report['mad_fh_integration']
        print(f"   MAD-FHçµ±åˆ:")
        print(f"     å‰å‡¦ç†: {'OK' if integration['preprocessor_compatible'] else 'NG'}")
        print(f"     FODD Pipeline: {'OK' if integration['fodd_compatible'] else 'NG'}")
        
        print(f"\nğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.data_dir}")
        print("="*60)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("ğŸš€ MVTec AD Wallplugs ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¤œè¨¼")
    print("å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®å“è³ªç¢ºèªã¨MAD-FHã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ†ã‚¹ãƒˆ")
    
    # æ¤œè¨¼å®Ÿè¡Œ
    validator = MVTecDataValidator("wallplugs")
    report = validator.generate_validation_report()
    validator.print_summary(report)
    
    print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. MAD-FHã‚·ã‚¹ãƒ†ãƒ ã§ã®ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("2. FODDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®å®Ÿéš›ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    print("3. ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆsheet_metal, wallnuts, fruit_jellyï¼‰ã®å‰å‡¦ç†")

if __name__ == "__main__":
    main()