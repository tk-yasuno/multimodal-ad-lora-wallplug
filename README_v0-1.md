# MAD-FH v0.1: Multimodal Anomaly Detector with Human Feedback

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

MAD-FHï¼ˆMultimodal Anomaly Detector with Human Feedbackï¼‰ã¯ã€è£½é€ æ¥­å‘ã‘ã®é«˜åº¦ãªç•°å¸¸æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸç•°å¸¸æ¤œçŸ¥ã«åŠ ãˆã€äººé–“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ´»ç”¨ã—ãŸAIèª¬æ˜ç”Ÿæˆã€ãã—ã¦å®Œå…¨ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿è¨˜è¿°ï¼ˆFODDï¼‰ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã—ãŸåŒ…æ‹¬çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½

- **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç•°å¸¸æ¤œçŸ¥**: ç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®è‡ªå‹•ç•°å¸¸æ¤œçŸ¥
- **äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯çµ±åˆ**: å°‚é–€å®¶ã®çŸ¥è¦‹ã‚’æ´»ç”¨ã—ãŸå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
- **AIèª¬æ˜ç”Ÿæˆ**: LoRAã‚’ç”¨ã„ãŸè‡ªç„¶è¨€èªã§ã®ç•°å¸¸èª¬æ˜ç”Ÿæˆ
- **ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†**: è“„ç©ã•ã‚ŒãŸçŸ¥è­˜ã®åŠ¹ç‡çš„ãªç®¡ç†ãƒ»æ¤œç´¢
- **FODDå³æ™‚åˆ†æ**: æ–°è¦ç”»åƒã«å¯¾ã™ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æãƒ»èª¬æ˜ç”Ÿæˆ
- **Web UI**: Streamlitãƒ™ãƒ¼ã‚¹ã®ç›´æ„Ÿçš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### ã‚¹ãƒ†ãƒƒãƒ—1-7 å®Œå…¨å®Ÿè£…æ¸ˆã¿

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Step 1-2      â”‚    â”‚    Step 3-4      â”‚    â”‚    Step 5-6     â”‚
â”‚ ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ»å‰å‡¦ç†  â”‚ -> â”‚ ç•°å¸¸æ¤œçŸ¥ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ â”‚ -> â”‚ AIç”Ÿæˆãƒ»ãƒŠãƒ¬ãƒƒã‚¸   â”‚
â”‚ ImageProcessor  â”‚    â”‚ AnomalyDetector  â”‚    â”‚ LoRAGenerator   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   Step 7     â”‚
                            â”‚ FODD Pipelineâ”‚
                            â”‚ å³æ™‚åˆ†æçµ±åˆ   â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
MAD-FH/
â”œâ”€â”€ README_v0-1.md              # æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”œâ”€â”€ requirements.txt            # Pythonä¾å­˜é–¢ä¿‚
â”œâ”€â”€ launch_ui.py               # UIãƒ©ãƒ³ãƒãƒ£ãƒ¼
â”œâ”€â”€ fodd_pipeline.py           # FODDçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
â”œâ”€â”€ train_lora_model.py        # LoRAãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ manage_knowledge_base.py   # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†
â”œâ”€â”€ FODD_IMPLEMENTATION_REPORT.md  # å®Ÿè£…å®Œäº†å ±å‘Šæ›¸
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py      # ç”»åƒå‰å‡¦ç†ï¼ˆStep 1-2ï¼‰
â”‚   â”‚   â””â”€â”€ metadata_manager.py # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ autoencoder.py     # ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆStep 3ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ trainer.py         # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ streamlit_app.py   # ãƒ¡ã‚¤ãƒ³UI
â”‚   â”‚   â””â”€â”€ feedback_manager.py # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç®¡ç†ï¼ˆStep 4ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ lora/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multimodal_model.py # LoRAãƒ¢ãƒ‡ãƒ«ï¼ˆStep 5-6ï¼‰
â”‚   â”‚   â””â”€â”€ explanation_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ knowledge_base/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ knowledge_manager.py # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ï¼ˆStep 6ï¼‰
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py          # ãƒ­ã‚°ç®¡ç†
â”‚
â”œâ”€â”€ data/                      # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”œâ”€â”€ models/                    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ logs/                      # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â””â”€â”€ tests/                     # ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### 1. ç’°å¢ƒè¦ä»¶

- Python 3.8+
- CUDAå¯¾å¿œGPUï¼ˆæ¨å¥¨ã€CPUä½¿ç”¨ã‚‚å¯èƒ½ï¼‰
- 8GBä»¥ä¸Šã®RAM
- 10GBä»¥ä¸Šã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸

### 2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository-url>
cd MAD-FH

# 2. ä»®æƒ³ç’°å¢ƒä½œæˆãƒ»æœ‰åŠ¹åŒ–
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# 3. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 4. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
# config/config.yaml ã®è¨­å®šã‚’ç’°å¢ƒã«åˆã‚ã›ã¦èª¿æ•´
```

### 3. åˆæœŸè¨­å®š

```yaml
# config/config.yaml ã®ä¸»è¦è¨­å®š
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed" 
  image_size: [224, 224]

models:
  autoencoder:
    latent_dim: 256
    anomaly_threshold: 0.1

fodd:
  anomaly_detection:
    threshold: 0.1
  similarity_search:
    top_k: 5
  text_generation:
    max_length: 150
```

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### 1. Web UIèµ·å‹•ï¼ˆæ¨å¥¨ï¼‰

```bash
# Streamlit Web UIã‚’èµ·å‹•
python launch_ui.py --ui streamlit

# ã¾ãŸã¯ç›´æ¥èµ·å‹•
python -m streamlit run src/ui/streamlit_app.py --server.port 8502
```

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:8502` ã«ã‚¢ã‚¯ã‚»ã‚¹

### 2. å„æ©Ÿèƒ½ã®ä½¿ç”¨æ–¹æ³•

#### ğŸ“Š ç”»åƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆStep 1-4ï¼‰
1. Web UIã§ã€Œç”»åƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã€ãƒšãƒ¼ã‚¸é¸æŠ
2. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
3. ç•°å¸¸æ¤œçŸ¥çµæœã‚’ç¢ºèª
4. ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æƒ…å ±ã‚’å…¥åŠ›ãƒ»ä¿å­˜

#### ğŸ¤– AIèª¬æ˜ç”Ÿæˆï¼ˆStep 5-6ï¼‰
1. ã€ŒAIèª¬æ˜ç”Ÿæˆã€ãƒšãƒ¼ã‚¸é¸æŠ
2. åˆ†æå¯¾è±¡ç”»åƒã‚’é¸æŠ
3. LoRAãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹èª¬æ˜æ–‡ç”Ÿæˆ
4. ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¨ã®çµ±åˆç¢ºèª

#### ğŸš€ FODDå³æ™‚åˆ†æï¼ˆStep 7ï¼‰
1. ã€ŒFODDå³æ™‚åˆ†æã€ãƒšãƒ¼ã‚¸é¸æŠ
2. æ–°è¦ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æå®Ÿè¡Œ
4. ç•°å¸¸åˆ¤å®šãƒ»èª¬æ˜ãƒ»é¡ä¼¼äº‹ä¾‹ã‚’ç¢ºèª

### 3. ãƒ—ãƒ­ã‚°ãƒ©ãƒ APIä½¿ç”¨

#### ç•°å¸¸æ¤œçŸ¥

```python
from src.models.autoencoder import AnomalyDetector
from src.data.preprocess import ImagePreprocessor

# ç”»åƒå‰å‡¦ç†
preprocessor = ImagePreprocessor("config/config.yaml")
processed_image = preprocessor.preprocess_single_image("image.jpg")

# ç•°å¸¸æ¤œçŸ¥
detector = AnomalyDetector.load_model("models/autoencoder_best.pth")
is_anomaly, score = detector.predict(processed_image)
```

#### FODDçµ±åˆåˆ†æ

```python
from fodd_pipeline import FODDPipeline

# FODD PipelineåˆæœŸåŒ–
pipeline = FODDPipeline()

# å˜ä¸€ç”»åƒåˆ†æ
result = pipeline.process_single_image("new_image.jpg")
print(f"ç•°å¸¸åˆ¤å®š: {result['anomaly_detection']['is_anomaly']}")
print(f"ç”Ÿæˆèª¬æ˜: {result['generated_description']}")

# ãƒãƒƒãƒå‡¦ç†
results = pipeline.process_batch_images(["img1.jpg", "img2.jpg"])
```

#### ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†

```python
from src.knowledge_base.knowledge_manager import KnowledgeBaseManager

# ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
kb_manager = KnowledgeBaseManager(config)

# çŸ¥è­˜è¿½åŠ 
kb_manager.add_knowledge(image_features, metadata, explanation)

# é¡ä¼¼æ¤œç´¢
similar_cases = kb_manager.search_similar(query_features, top_k=5)
```

## ğŸ“ˆ å„ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°å®Ÿè£…

### Step 1-2: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ»å‰å‡¦ç† âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `src/data/preprocess.py`, `src/data/metadata_manager.py`
- **æ©Ÿèƒ½**: ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

### Step 3: ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `src/models/autoencoder.py`, `src/training/trainer.py`
- **æ©Ÿèƒ½**: ConvAutoencoderã«ã‚ˆã‚‹ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

### Step 4: äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›† âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `src/ui/feedback_manager.py`, `src/ui/streamlit_app.py`
- **æ©Ÿèƒ½**: Web UIã§ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†ãƒ»ç®¡ç†
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

### Step 5: AIèª¬æ˜ç”Ÿæˆ âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `src/lora/multimodal_model.py`, `train_lora_model.py`
- **æ©Ÿèƒ½**: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹èª¬æ˜æ–‡ç”Ÿæˆ
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

### Step 6: ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆ âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `src/knowledge_base/knowledge_manager.py`
- **æ©Ÿèƒ½**: ç‰¹å¾´é‡ãƒ»èª¬æ˜æ–‡ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆç®¡ç†
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

### Step 7: FODDå®Œå…¨çµ±åˆ âœ…
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `fodd_pipeline.py`, Streamlit UIçµ±åˆ
- **æ©Ÿèƒ½**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”»åƒåˆ†æãƒ»èª¬æ˜ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
- **å®Ÿè£…**: å®Œäº†æ¸ˆã¿

## ğŸ”§ é–‹ç™ºãƒ»æ‹¡å¼µ

### ãƒ¢ãƒ‡ãƒ«å­¦ç¿’

```bash
# LoRAãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼‰
python train_lora_model.py --demo --force-dummy

# ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
python -c "from src.training.trainer import train_autoencoder; train_autoencoder()"
```

### ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç®¡ç†

```bash
# ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒ»ç®¡ç†
python manage_knowledge_base.py

# ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
python test_knowledge_base.py
```

### ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

```bash
# FODDçµ±åˆãƒ†ã‚¹ãƒˆ
python simple_fodd_test.py
python fodd_ui_test.py

# åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ
python test_fodd_integration.py
```

## ğŸ“Š è¨­å®šãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### config/config.yaml ä¸»è¦è¨­å®š

```yaml
# ãƒ‡ãƒ¼ã‚¿å‡¦ç†è¨­å®š
data:
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  image_size: [224, 224]
  batch_size: 32

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
models:
  autoencoder:
    input_channels: 3
    latent_dim: 256
    learning_rate: 0.001
    anomaly_threshold: 0.1

# LoRAè¨­å®š
lora:
  model_name: "Salesforce/blip2-opt-2.7b"
  lora_rank: 16
  lora_alpha: 32
  target_modules: ["q_proj", "v_proj"]

# FODDè¨­å®š
fodd:
  anomaly_detection:
    threshold: 0.1
    confidence_threshold: 0.8
  similarity_search:
    top_k: 5
    similarity_threshold: 0.7
  text_generation:
    max_length: 150
    temperature: 0.7
  reporting:
    output_dir: "data/reports"
    include_similar_cases: true
  notification:
    enabled: false
    slack_webhook_url: ""
```

## ğŸŒ Web UIæ©Ÿèƒ½è©³ç´°

### ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸
- ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç›£è¦–
- æœ€æ–°åˆ†æçµæœã‚µãƒãƒªãƒ¼
- ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãƒ¡ãƒ‹ãƒ¥ãƒ¼

### ç”»åƒãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
- ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»è¡¨ç¤º
- ç•°å¸¸æ¤œçŸ¥çµæœè¡¨ç¤º
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯å±¥æ­´ç®¡ç†

### AIèª¬æ˜ç”Ÿæˆ
- LoRAãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª
- èª¬æ˜æ–‡ç”Ÿæˆãƒ»è¡¨ç¤º
- ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
- å“è³ªè©•ä¾¡ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

### FODDå³æ™‚åˆ†æ
- **å˜ä¸€ç”»åƒåˆ†æ**: 1æšã®ç”»åƒã‚’å³åº§ã«åˆ†æ
- **ãƒãƒƒãƒåˆ†æ**: è¤‡æ•°ç”»åƒã®ä¸€æ‹¬å‡¦ç†
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–**: ç¶™ç¶šçš„ãªç›£è¦–æ©Ÿèƒ½
- **çµæœå¯è¦–åŒ–**: ç•°å¸¸ã‚¹ã‚³ã‚¢ãƒ»é¡ä¼¼äº‹ä¾‹ãƒ»èª¬æ˜æ–‡è¡¨ç¤º

### ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹
- è“„ç©ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãƒ»é–²è¦§
- é¡ä¼¼äº‹ä¾‹æ¤œç´¢
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆæƒ…å ±
- ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½

### ãƒ‡ãƒ¼ã‚¿åˆ†æ
- ç•°å¸¸æ¤œçŸ¥çµ±è¨ˆ
- ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ
- ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡
- ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ

### ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
- ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç›£è¦–
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™
- ãƒ­ã‚°è¡¨ç¤º
- ã‚·ã‚¹ãƒ†ãƒ è¨­å®š

## ğŸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### 1. ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„
```
âš ï¸ models/autoencoder_best.pth (å­˜åœ¨ã—ã¾ã›ã‚“)
âš ï¸ models/lora_model (å­˜åœ¨ã—ã¾ã›ã‚“)
```
**è§£æ±ºæ–¹æ³•**: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ
```bash
python train_lora_model.py --demo --force-dummy
```

#### 2. GPU ãƒ¡ãƒ¢ãƒªä¸è¶³
**è§£æ±ºæ–¹æ³•**: config.yamlã§ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’èª¿æ•´
```yaml
data:
  batch_size: 16  # 32ã‹ã‚‰16ã«æ¸›å°‘
```

#### 3. Streamlitèµ·å‹•ã‚¨ãƒ©ãƒ¼
**è§£æ±ºæ–¹æ³•**: ãƒãƒ¼ãƒˆç«¶åˆç¢ºèªãƒ»å¤‰æ›´
```bash
python -m streamlit run src/ui/streamlit_app.py --server.port 8503
```

#### 4. ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼
**è§£æ±ºæ–¹æ³•**: Python pathã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ç¢ºèª
```bash
export PYTHONPATH="${PYTHONPATH}:$(pwd)"  # Linux/Mac
set PYTHONPATH=%PYTHONPATH%;%CD%  # Windows
```

### ãƒ­ã‚°ç¢ºèª

```bash
# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
tail -f logs/mad_fh.log

# è©³ç´°ãƒ‡ãƒãƒƒã‚°
python -c "import logging; logging.basicConfig(level=logging.DEBUG)"
```

## ğŸ“š æŠ€è¡“ä»•æ§˜

### ä¾å­˜é–¢ä¿‚
- **Deep Learning**: PyTorch, transformers, peft
- **Image Processing**: OpenCV, PIL, albumentations
- **Web UI**: Streamlit
- **Data**: pandas, numpy, yaml
- **Visualization**: plotly, matplotlib

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
- **ç”»åƒå‡¦ç†**: ~100ms/ç”»åƒï¼ˆGPUä½¿ç”¨æ™‚ï¼‰
- **ç•°å¸¸æ¤œçŸ¥**: ~50ms/ç”»åƒ
- **èª¬æ˜ç”Ÿæˆ**: ~2-3ç§’/ç”»åƒï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºä¾å­˜ï¼‰
- **UIå¿œç­”**: <1ç§’

### ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£
- **ãƒãƒƒãƒå‡¦ç†**: 1000æš/æ™‚é–“ï¼ˆæ¨™æº–è¨­å®šï¼‰
- **åŒæ™‚æ¥ç¶š**: 10-50ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆStreamlitåˆ¶é™ï¼‰
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: 100ä¸‡ä»¶/ãƒ†ãƒ¼ãƒ–ãƒ«

## ğŸ”® ä»Šå¾Œã®æ‹¡å¼µäºˆå®š

### Phase 2 æ©Ÿèƒ½
- [ ] ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆ†æ
- [ ] å¤šè¨€èªèª¬æ˜ç”Ÿæˆå¯¾å¿œ
- [ ] REST APIæä¾›
- [ ] Docker containerization
- [ ] ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆå¯¾å¿œ

### Phase 3 æ©Ÿèƒ½
- [ ] ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
- [ ] A/Bãƒ†ã‚¹ãƒˆæ©Ÿèƒ½
- [ ] é«˜åº¦ãªå¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
- [ ] å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºAPI
- [ ] ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºèªè¨¼

## ğŸ‘¥ è²¢çŒ®ãƒ»é–‹ç™º

### é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-dev.txt

# pre-commitè¨­å®š
pre-commit install

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/
```

### ã‚³ãƒ¼ãƒ‰å“è³ª
- **Linting**: flake8, black
- **Type checking**: mypy
- **Testing**: pytest
- **Documentation**: Sphinx

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ MIT License ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ“ ã‚µãƒãƒ¼ãƒˆãƒ»ãŠå•ã„åˆã‚ã›

- **Issues**: GitHub Issues
- **Documentation**: `/docs` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
- **Examples**: `/notebooks` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

---

## ğŸ‰ Version 0.1 å®Ÿè£…å®Œäº†

**MAD-FH v0.1ã¯å…¨7ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè£…ãŒå®Œäº†ã—ã€è£½é€ æ¥­å‘ã‘ã®åŒ…æ‹¬çš„ãªç•°å¸¸æ¤œçŸ¥ãƒ»èª¬æ˜ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã¨ã—ã¦é‹ç”¨å¯èƒ½ã§ã™ã€‚**

- âœ… Step 1-2: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ»å‰å‡¦ç†
- âœ… Step 3: ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
- âœ… Step 4: äººé–“ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†
- âœ… Step 5: AIèª¬æ˜ç”Ÿæˆï¼ˆLoRAï¼‰
- âœ… Step 6: ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆ
- âœ… Step 7: FODDå®Œå…¨çµ±åˆ

**å³åº§ã«åˆ©ç”¨é–‹å§‹å¯èƒ½**: `python launch_ui.py --ui streamlit`

---

*æœ€çµ‚æ›´æ–°: 2024å¹´12æœˆ | Version: 0.1.0 | Status: Production Ready*
